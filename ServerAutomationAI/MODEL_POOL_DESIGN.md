# ğŸ¯ ØªØµÙ…ÙŠÙ… Model Pool Manager - Ø¯Ù„ÙŠÙ„ Ø§Ù„ØªÙ†ÙÙŠØ° Ø§Ù„ÙƒØ§Ù…Ù„

**Ø§Ù„Ù‡Ø¯Ù:** Ù†Ø¸Ø§Ù… Ù…Ø±ÙƒØ²ÙŠ Ù„Ø¥Ø¯Ø§Ø±Ø© Ù†Ù…Ø§Ø°Ø¬ AI Ù…ØªØ¹Ø¯Ø¯Ø© (Ù…Ø¬Ø§Ù†ÙŠØ© ÙˆÙ…Ø¯ÙÙˆØ¹Ø©) Ù…Ø¹ failover Ø°ÙƒÙŠ ÙˆØ¥Ø¯Ø§Ø±Ø© ØªÙƒØ§Ù„ÙŠÙ

---

## ğŸ“ Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„Ù…Ø¹Ù…Ø§Ø±ÙŠØ©

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   MODEL POOL MANAGER                        â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚   Registry   â”‚  â”‚   Router     â”‚  â”‚   Monitor    â”‚     â”‚
â”‚  â”‚   (Models)   â”‚  â”‚  (Selection) â”‚  â”‚  (Health)    â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚         â”‚                   â”‚                  â”‚           â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                           â”‚                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚ Key Manager  â”‚ Usage Tracker     â”‚ Cost Manager â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚            â”‚            â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Free    â”‚  â”‚  Paid    â”‚  â”‚  Fallback  â”‚
    â”‚  Models  â”‚  â”‚  Models  â”‚  â”‚  (Cache)   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ—‚ï¸ Ù‡ÙŠÙƒÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª

```
model_pool/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ manager.py              # ModelPoolManager Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
â”œâ”€â”€ models.py               # Model classes & configurations
â”œâ”€â”€ key_manager.py          # Ø¥Ø¯Ø§Ø±Ø© API Keys
â”œâ”€â”€ usage_tracker.py        # ØªØªØ¨Ø¹ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙˆØ§Ù„ØªÙƒØ§Ù„ÙŠÙ
â”œâ”€â”€ router.py               # Model selection logic
â”œâ”€â”€ monitor.py              # Health monitoring
â”œâ”€â”€ cost_manager.py         # Cost optimization
â”œâ”€â”€ providers/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base.py            # BaseProvider interface
â”‚   â”œâ”€â”€ openai_provider.py
â”‚   â”œâ”€â”€ anthropic_provider.py
â”‚   â”œâ”€â”€ google_provider.py
â”‚   â”œâ”€â”€ groq_provider.py
â”‚   â”œâ”€â”€ cohere_provider.py
â”‚   â””â”€â”€ mistral_provider.py
â””â”€â”€ utils/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ encryption.py      # Key encryption
    â”œâ”€â”€ cache.py           # Response caching
    â””â”€â”€ retry.py           # Retry logic
```

---

## ğŸ“ Ø§Ù„ØªÙ†ÙÙŠØ° Ø§Ù„ØªÙØµÙŠÙ„ÙŠ

### 1. Model Configuration (models.py)

```python
from dataclasses import dataclass
from typing import List, Optional
from enum import Enum

class ModelTier(Enum):
    FREE = "free"
    PAID = "paid"
    PREMIUM = "premium"

class ModelCapability(Enum):
    REASONING = "reasoning"
    CODING = "coding"
    VISION = "vision"
    ANALYSIS = "analysis"
    FAST = "fast"
    LARGE_CONTEXT = "large_context"

@dataclass
class ModelConfig:
    """ØªÙƒÙˆÙŠÙ† Ù†Ù…ÙˆØ°Ø¬ AI"""
    
    model_id: str
    provider: str
    model_name: str
    tier: ModelTier
    
    cost_per_1k_input_tokens: float = 0.0
    cost_per_1k_output_tokens: float = 0.0
    
    rpm_limit: int = 60
    tpm_limit: int = 100000
    context_window: int = 128000
    
    capabilities: List[ModelCapability] = None
    
    max_output_tokens: int = 4096
    temperature_default: float = 0.7
    
    is_active: bool = True
    is_experimental: bool = False
    
    priority: int = 5
    
    metadata: dict = None
    
    def __post_init__(self):
        if self.capabilities is None:
            self.capabilities = []
        if self.metadata is None:
            self.metadata = {}

@dataclass
class ModelResponse:
    """Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ù…Ù† Ù†Ù…ÙˆØ°Ø¬"""
    
    model_id: str
    provider: str
    
    content: str
    
    tokens_used: int
    input_tokens: int
    output_tokens: int
    
    cost: float
    response_time_ms: int
    
    success: bool
    error_message: Optional[str] = None
    
    cached: bool = False
    
    metadata: dict = None
```

### 2. Base Provider (providers/base.py)

```python
from abc import ABC, abstractmethod
from typing import Optional, Dict, Any

class BaseProvider(ABC):
    """
    ÙˆØ§Ø¬Ù‡Ø© Ù…ÙˆØ­Ø¯Ø© Ù„Ø¬Ù…ÙŠØ¹ Ù…Ø²ÙˆØ¯ÙŠ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
    """
    
    def __init__(self, api_key: str, config: Dict[str, Any] = None):
        self.api_key = api_key
        self.config = config or {}
        
    @abstractmethod
    async def complete(
        self,
        prompt: str,
        model: str,
        temperature: float = 0.7,
        max_tokens: int = 4096,
        **kwargs
    ) -> ModelResponse:
        """
        Ø¥Ø±Ø³Ø§Ù„ Ø·Ù„Ø¨ Ù„Ù„Ù†Ù…ÙˆØ°Ø¬
        
        Args:
            prompt: Ø§Ù„Ù†Øµ Ø§Ù„Ù…ÙØ¯Ø®Ù„
            model: Ø§Ø³Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            temperature: Ø¯Ø±Ø¬Ø© Ø§Ù„Ø¥Ø¨Ø¯Ø§Ø¹
            max_tokens: Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ù„Ù€ tokens
            **kwargs: Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©
            
        Returns:
            ModelResponse
        """
        pass
    
    @abstractmethod
    async def test_connection(self) -> bool:
        """Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ù€ API"""
        pass
    
    @abstractmethod
    def get_usage_info(self) -> Dict[str, Any]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…"""
        pass
    
    def calculate_cost(
        self,
        model_config: ModelConfig,
        input_tokens: int,
        output_tokens: int
    ) -> float:
        """Ø­Ø³Ø§Ø¨ ØªÙƒÙ„ÙØ© Ø§Ù„Ø·Ù„Ø¨"""
        input_cost = (input_tokens / 1000) * model_config.cost_per_1k_input_tokens
        output_cost = (output_tokens / 1000) * model_config.cost_per_1k_output_tokens
        return input_cost + output_cost
```

### 3. OpenAI Provider (providers/openai_provider.py)

```python
import openai
from typing import Dict, Any
import time
from .base import BaseProvider, ModelResponse

class OpenAIProvider(BaseProvider):
    """Ù…Ø²ÙˆØ¯ OpenAI (GPT-4, GPT-3.5)"""
    
    def __init__(self, api_key: str, config: Dict[str, Any] = None):
        super().__init__(api_key, config)
        self.client = openai.AsyncOpenAI(api_key=api_key)
    
    async def complete(
        self,
        prompt: str,
        model: str,
        temperature: float = 0.7,
        max_tokens: int = 4096,
        **kwargs
    ) -> ModelResponse:
        """Ø¥Ø±Ø³Ø§Ù„ Ø·Ù„Ø¨ Ù„Ù€ OpenAI"""
        
        start_time = time.time()
        
        try:
            response = await self.client.chat.completions.create(
                model=model,
                messages=[{"role": "user", "content": prompt}],
                temperature=temperature,
                max_tokens=max_tokens,
                **kwargs
            )
            
            response_time_ms = int((time.time() - start_time) * 1000)
            
            usage = response.usage
            content = response.choices[0].message.content
            
            return ModelResponse(
                model_id=f"openai_{model}",
                provider="openai",
                content=content,
                tokens_used=usage.total_tokens,
                input_tokens=usage.prompt_tokens,
                output_tokens=usage.completion_tokens,
                cost=0.0,  # Will be calculated by manager
                response_time_ms=response_time_ms,
                success=True
            )
            
        except Exception as e:
            response_time_ms = int((time.time() - start_time) * 1000)
            
            return ModelResponse(
                model_id=f"openai_{model}",
                provider="openai",
                content="",
                tokens_used=0,
                input_tokens=0,
                output_tokens=0,
                cost=0.0,
                response_time_ms=response_time_ms,
                success=False,
                error_message=str(e)
            )
    
    async def test_connection(self) -> bool:
        """Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø§ØªØµØ§Ù„"""
        try:
            await self.client.models.list()
            return True
        except:
            return False
    
    def get_usage_info(self) -> Dict[str, Any]:
        """Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… (OpenAI Ù„Ø§ ÙŠÙˆÙØ± API Ù„Ù‡Ø°Ø§)"""
        return {"provider": "openai", "note": "No usage API available"}
```

### 4. Groq Provider (Ù…Ø¬Ø§Ù†ÙŠ)

```python
from groq import AsyncGroq
from .base import BaseProvider, ModelResponse
import time

class GroqProvider(BaseProvider):
    """Ù…Ø²ÙˆØ¯ Groq (Ù…Ø¬Ø§Ù†ÙŠ - Llama 3.3 70B)"""
    
    def __init__(self, api_key: str, config: Dict[str, Any] = None):
        super().__init__(api_key, config)
        self.client = AsyncGroq(api_key=api_key)
    
    async def complete(
        self,
        prompt: str,
        model: str = "llama-3.3-70b-versatile",
        temperature: float = 0.7,
        max_tokens: int = 4096,
        **kwargs
    ) -> ModelResponse:
        """Ø¥Ø±Ø³Ø§Ù„ Ø·Ù„Ø¨ Ù„Ù€ Groq"""
        
        start_time = time.time()
        
        try:
            response = await self.client.chat.completions.create(
                model=model,
                messages=[{"role": "user", "content": prompt}],
                temperature=temperature,
                max_tokens=max_tokens,
                **kwargs
            )
            
            response_time_ms = int((time.time() - start_time) * 1000)
            
            usage = response.usage
            content = response.choices[0].message.content
            
            return ModelResponse(
                model_id=f"groq_{model}",
                provider="groq",
                content=content,
                tokens_used=usage.total_tokens,
                input_tokens=usage.prompt_tokens,
                output_tokens=usage.completion_tokens,
                cost=0.0,  # Free!
                response_time_ms=response_time_ms,
                success=True
            )
            
        except Exception as e:
            response_time_ms = int((time.time() - start_time) * 1000)
            
            return ModelResponse(
                model_id=f"groq_{model}",
                provider="groq",
                content="",
                tokens_used=0,
                input_tokens=0,
                output_tokens=0,
                cost=0.0,
                response_time_ms=response_time_ms,
                success=False,
                error_message=str(e)
            )
    
    async def test_connection(self) -> bool:
        """Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø§ØªØµØ§Ù„"""
        try:
            await self.complete("test", max_tokens=10)
            return True
        except:
            return False
    
    def get_usage_info(self) -> Dict[str, Any]:
        """Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…"""
        return {
            "provider": "groq",
            "tier": "free",
            "rpm_limit": 30,
            "tpm_limit": 15000
        }
```

### 5. Model Pool Manager (manager.py)

```python
import asyncio
from typing import Dict, List, Optional
from datetime import datetime
import yaml
from pathlib import Path

from .models import ModelConfig, ModelResponse, ModelTier
from .key_manager import APIKeyManager
from .usage_tracker import UsageTracker
from .router import ModelRouter
from .cost_manager import CostManager
from .providers import *

class ModelPoolManager:
    """
    Ø§Ù„Ù…Ø¯ÙŠØ± Ø§Ù„Ù…Ø±ÙƒØ²ÙŠ Ù„Ø¬Ù…ÙŠØ¹ Ù†Ù…Ø§Ø°Ø¬ AI
    
    Features:
    - ØªØ³Ø¬ÙŠÙ„ Ù†Ù…Ø§Ø°Ø¬ Ù…ØªØ¹Ø¯Ø¯Ø©
    - Ø§Ø®ØªÙŠØ§Ø± Ø°ÙƒÙŠ Ù„Ù„Ù†Ù…ÙˆØ°Ø¬
    - Failover ØªÙ„Ù‚Ø§Ø¦ÙŠ
    - ØªØªØ¨Ø¹ Ø§Ù„ØªÙƒØ§Ù„ÙŠÙ
    - Ø¥Ø¯Ø§Ø±Ø© API Keys
    """
    
    def __init__(self, config_path: str = "configs/models.yaml"):
        self.config_path = Path(config_path)
        self.models: Dict[str, ModelConfig] = {}
        self.providers: Dict[str, BaseProvider] = {}
        
        self.key_manager = APIKeyManager()
        self.usage_tracker = UsageTracker()
        self.router = ModelRouter(self)
        self.cost_manager = CostManager(self)
        
        self._load_config()
        self._initialize_providers()
        
    def _load_config(self):
        """ØªØ­Ù…ÙŠÙ„ ØªÙƒÙˆÙŠÙ†Ø§Øª Ø§Ù„Ù†Ù…Ø§Ø°Ø¬"""
        if not self.config_path.exists():
            raise FileNotFoundError(f"Config not found: {self.config_path}")
            
        with open(self.config_path, 'r') as f:
            config = yaml.safe_load(f)
        
        for tier_name, models_list in config.get('models', {}).items():
            tier = ModelTier(tier_name.replace('_tier', ''))
            
            for model_conf in models_list:
                model = ModelConfig(
                    model_id=model_conf['id'],
                    provider=model_conf['provider'],
                    model_name=model_conf['model'],
                    tier=tier,
                    cost_per_1k_input_tokens=model_conf.get('cost_per_1k_tokens', 0.0),
                    cost_per_1k_output_tokens=model_conf.get('cost_per_1k_tokens', 0.0),
                    rpm_limit=model_conf.get('rpm_limit', 60),
                    tpm_limit=model_conf.get('tpm_limit', 100000),
                    capabilities=[c for c in model_conf.get('capabilities', [])]
                )
                
                self.models[model.model_id] = model
    
    def _initialize_providers(self):
        """ØªÙ‡ÙŠØ¦Ø© Ù…Ø²ÙˆØ¯ÙŠ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬"""
        
        provider_classes = {
            'openai': OpenAIProvider,
            'anthropic': AnthropicProvider,
            'google': GoogleProvider,
            'groq': GroqProvider,
            'cohere': CohereProvider,
            'mistral': MistralProvider
        }
        
        for provider_name, provider_class in provider_classes.items():
            try:
                api_key = self.key_manager.get_key(provider_name)
                if api_key:
                    self.providers[provider_name] = provider_class(api_key)
            except Exception as e:
                print(f"Warning: Could not initialize {provider_name}: {e}")
    
    async def execute_task(
        self,
        prompt: str,
        task_type: str = "general",
        priority: str = "normal",
        preferred_tier: Optional[ModelTier] = None,
        **kwargs
    ) -> ModelResponse:
        """
        ØªÙ†ÙÙŠØ° Ù…Ù‡Ù…Ø© Ù…Ø¹ Ø§Ø®ØªÙŠØ§Ø± ØªÙ„Ù‚Ø§Ø¦ÙŠ Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨
        
        Args:
            prompt: Ø§Ù„Ù…ÙØ¯Ø®Ù„
            task_type: Ù†ÙˆØ¹ Ø§Ù„Ù…Ù‡Ù…Ø© (reasoning, coding, analysis, etc.)
            priority: Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ© (low, normal, high, critical)
            preferred_tier: Ø§Ù„Ø·Ø¨Ù‚Ø© Ø§Ù„Ù…ÙÙØ¶Ù„Ø© (free, paid, premium)
            
        Returns:
            ModelResponse
        """
        
        # 1. Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨
        selected_model = await self.router.select_model(
            task_type=task_type,
            priority=priority,
            preferred_tier=preferred_tier
        )
        
        if not selected_model:
            return ModelResponse(
                model_id="none",
                provider="none",
                content="",
                tokens_used=0,
                input_tokens=0,
                output_tokens=0,
                cost=0.0,
                response_time_ms=0,
                success=False,
                error_message="No available model found"
            )
        
        # 2. Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„ØªÙ†ÙÙŠØ° Ù…Ø¹ fallback
        return await self._execute_with_fallback(selected_model, prompt, **kwargs)
    
    async def _execute_with_fallback(
        self,
        model_config: ModelConfig,
        prompt: str,
        max_retries: int = 3,
        **kwargs
    ) -> ModelResponse:
        """
        ØªÙ†ÙÙŠØ° Ù…Ø¹ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© ÙˆØ§Ù„Ù€ fallback
        """
        
        models_to_try = [model_config]
        
        # Ø¥Ø¶Ø§ÙØ© Ù†Ù…Ø§Ø°Ø¬ Ø¨Ø¯ÙŠÙ„Ø©
        fallback_models = self.router.get_fallback_models(model_config)
        models_to_try.extend(fallback_models[:2])
        
        last_error = None
        
        for model in models_to_try:
            provider = self.providers.get(model.provider)
            
            if not provider:
                continue
            
            for retry in range(max_retries):
                try:
                    response = await provider.complete(
                        prompt=prompt,
                        model=model.model_name,
                        **kwargs
                    )
                    
                    if response.success:
                        # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªÙƒÙ„ÙØ©
                        response.cost = provider.calculate_cost(
                            model,
                            response.input_tokens,
                            response.output_tokens
                        )
                        
                        # ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
                        await self.usage_tracker.track_request(
                            model_id=model.model_id,
                            tokens=response.tokens_used,
                            cost=response.cost,
                            success=True
                        )
                        
                        return response
                        
                except Exception as e:
                    last_error = e
                    await asyncio.sleep(1 * (retry + 1))
                    continue
        
        # Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø§Øª ÙØ´Ù„Øª
        return ModelResponse(
            model_id=model_config.model_id,
            provider=model_config.provider,
            content="",
            tokens_used=0,
            input_tokens=0,
            output_tokens=0,
            cost=0.0,
            response_time_ms=0,
            success=False,
            error_message=f"All models failed. Last error: {last_error}"
        )
    
    async def get_model_status(self, model_id: str) -> Dict:
        """Ø­Ø§Ù„Ø© Ù†Ù…ÙˆØ°Ø¬ Ù…Ø¹ÙŠÙ†"""
        model = self.models.get(model_id)
        
        if not model:
            return {"error": "Model not found"}
        
        provider = self.providers.get(model.provider)
        
        usage = await self.usage_tracker.get_model_usage(model_id)
        
        return {
            "model_id": model_id,
            "provider": model.provider,
            "tier": model.tier.value,
            "is_active": model.is_active,
            "usage_today": usage,
            "health": "ok" if provider else "no_provider"
        }
    
    async def get_system_status(self) -> Dict:
        """Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„ÙƒØ§Ù…Ù„Ø©"""
        
        total_models = len(self.models)
        active_models = len([m for m in self.models.values() if m.is_active])
        
        daily_usage = await self.usage_tracker.get_daily_usage()
        daily_cost = await self.cost_manager.get_daily_cost()
        
        return {
            "total_models": total_models,
            "active_models": active_models,
            "providers": list(self.providers.keys()),
            "daily_requests": daily_usage.get('total_requests', 0),
            "daily_tokens": daily_usage.get('total_tokens', 0),
            "daily_cost": daily_cost,
            "cost_budget": self.cost_manager.daily_budget,
            "cost_remaining": max(0, self.cost_manager.daily_budget - daily_cost)
        }
```

### 6. Model Router (router.py)

```python
from typing import Optional, List
from .models import ModelConfig, ModelTier, ModelCapability

class ModelRouter:
    """
    Ù…Ø­Ø±Ùƒ Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø°ÙƒÙŠ
    """
    
    def __init__(self, pool_manager):
        self.pool = pool_manager
        
    async def select_model(
        self,
        task_type: str = "general",
        priority: str = "normal",
        preferred_tier: Optional[ModelTier] = None
    ) -> Optional[ModelConfig]:
        """
        Ø§Ø®ØªÙŠØ§Ø± Ø£ÙØ¶Ù„ Ù†Ù…ÙˆØ°Ø¬ Ù„Ù„Ù…Ù‡Ù…Ø©
        
        Logic:
        1. ÙÙ„ØªØ±Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø© Ø­Ø³Ø¨ task_type
        2. ØªØ±ØªÙŠØ¨ Ø­Ø³Ø¨ Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ© ÙˆØ§Ù„ØªÙƒÙ„ÙØ©
        3. ÙØ­Øµ Ø§Ù„Ù€ quota Ø§Ù„Ù…ØªØ¨Ù‚ÙŠØ©
        4. Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø£ÙØ¶Ù„
        """
        
        # 1. Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù†Ø´Ø·Ø© ÙÙ‚Ø·
        available_models = [
            m for m in self.pool.models.values()
            if m.is_active
        ]
        
        # 2. ÙÙ„ØªØ±Ø© Ø­Ø³Ø¨ Ø§Ù„Ø·Ø¨Ù‚Ø© Ø§Ù„Ù…ÙØ¶Ù„Ø©
        if preferred_tier:
            available_models = [
                m for m in available_models
                if m.tier == preferred_tier
            ]
        
        # 3. ÙÙ„ØªØ±Ø© Ø­Ø³Ø¨ Ø§Ù„Ù‚Ø¯Ø±Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
        required_capability = self._map_task_to_capability(task_type)
        
        if required_capability:
            available_models = [
                m for m in available_models
                if required_capability in m.capabilities
            ]
        
        # 4. ÙØ­Øµ Ø§Ù„Ù€ quota
        models_with_quota = []
        for model in available_models:
            has_quota = await self._check_quota(model)
            if has_quota:
                models_with_quota.append(model)
        
        if not models_with_quota:
            return None
        
        # 5. ØªØ±ØªÙŠØ¨ ÙˆØ¥Ø±Ø¬Ø§Ø¹ Ø§Ù„Ø£ÙØ¶Ù„
        sorted_models = self._sort_models(models_with_quota, priority)
        
        return sorted_models[0] if sorted_models else None
    
    def _map_task_to_capability(self, task_type: str) -> Optional[ModelCapability]:
        """ØªØ­ÙˆÙŠÙ„ Ù†ÙˆØ¹ Ø§Ù„Ù…Ù‡Ù…Ø© Ø¥Ù„Ù‰ Ù‚Ø¯Ø±Ø© Ù…Ø·Ù„ÙˆØ¨Ø©"""
        
        mapping = {
            "coding": ModelCapability.CODING,
            "analysis": ModelCapability.ANALYSIS,
            "reasoning": ModelCapability.REASONING,
            "vision": ModelCapability.VISION,
            "fast": ModelCapability.FAST
        }
        
        return mapping.get(task_type)
    
    async def _check_quota(self, model: ModelConfig) -> bool:
        """ÙØ­Øµ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ø¯ÙŠÙ‡ quota Ù…ØªØ¨Ù‚ÙŠØ©"""
        
        usage = await self.pool.usage_tracker.get_model_usage(model.model_id)
        
        requests_today = usage.get('requests_today', 0)
        tokens_today = usage.get('tokens_today', 0)
        
        rpm_ok = requests_today < model.rpm_limit * 24 * 60
        tpm_ok = tokens_today < model.tpm_limit * 24 * 60
        
        return rpm_ok and tpm_ok
    
    def _sort_models(
        self,
        models: List[ModelConfig],
        priority: str
    ) -> List[ModelConfig]:
        """ØªØ±ØªÙŠØ¨ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø­Ø³Ø¨ Ø§Ù„Ø£ÙØ¶Ù„ÙŠØ©"""
        
        if priority == "low":
            # Ø§Ù„Ù…Ø¬Ø§Ù†ÙŠ Ø£ÙˆÙ„Ø§Ù‹ØŒ Ø«Ù… Ø§Ù„Ø£Ø±Ø®Øµ
            return sorted(
                models,
                key=lambda m: (m.tier.value, m.cost_per_1k_input_tokens)
            )
        elif priority == "critical":
            # Ø§Ù„Ø£ÙØ¶Ù„ Ø£ÙˆÙ„Ø§Ù‹ØŒ Ø¨ØºØ¶ Ø§Ù„Ù†Ø¸Ø± Ø¹Ù† Ø§Ù„ØªÙƒÙ„ÙØ©
            return sorted(
                models,
                key=lambda m: (-m.priority, m.tier.value)
            )
        else:
            # ØªÙˆØ§Ø²Ù† Ø¨ÙŠÙ† Ø§Ù„Ø¬ÙˆØ¯Ø© ÙˆØ§Ù„ØªÙƒÙ„ÙØ©
            return sorted(
                models,
                key=lambda m: (m.tier.value, -m.priority)
            )
    
    def get_fallback_models(
        self,
        model: ModelConfig,
        max_fallbacks: int = 3
    ) -> List[ModelConfig]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù†Ù…Ø§Ø°Ø¬ Ø¨Ø¯ÙŠÙ„Ø©"""
        
        fallbacks = []
        
        for m in self.pool.models.values():
            if m.model_id == model.model_id:
                continue
            
            if m.is_active and m.tier in [ModelTier.FREE, model.tier]:
                fallbacks.append(m)
        
        fallbacks.sort(key=lambda m: (m.tier.value, m.cost_per_1k_input_tokens))
        
        return fallbacks[:max_fallbacks]
```

---

## ğŸ”‘ API Key Manager (key_manager.py)

```python
from cryptography.fernet import Fernet
import os
from pathlib import Path
import json

class APIKeyManager:
    """
    Ø¥Ø¯Ø§Ø±Ø© Ø¢Ù…Ù†Ø© Ù„Ù€ API Keys
    
    Features:
    - ØªØ®Ø²ÙŠÙ† Ù…ÙØ´ÙØ±
    - Rotation
    - Access logging
    """
    
    def __init__(self, keys_file: str = ".api_keys.enc"):
        self.keys_file = Path(keys_file)
        self.cipher = self._get_cipher()
        self.keys = self._load_keys()
    
    def _get_cipher(self) -> Fernet:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…ÙØªØ§Ø­ Ø§Ù„ØªØ´ÙÙŠØ±"""
        
        key_env = os.getenv("ENCRYPTION_KEY")
        
        if not key_env:
            # Ø¥Ù†Ø´Ø§Ø¡ Ù…ÙØªØ§Ø­ Ø¬Ø¯ÙŠØ¯
            key = Fernet.generate_key()
            print(f"âš ï¸ Set ENCRYPTION_KEY={key.decode()}")
            return Fernet(key)
        
        return Fernet(key_env.encode())
    
    def _load_keys(self) -> dict:
        """ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙØ§ØªÙŠØ­ Ø§Ù„Ù…ÙØ´ÙØ±Ø©"""
        
        if not self.keys_file.exists():
            return {}
        
        encrypted_data = self.keys_file.read_bytes()
        decrypted_data = self.cipher.decrypt(encrypted_data)
        
        return json.loads(decrypted_data.decode())
    
    def _save_keys(self):
        """Ø­ÙØ¸ Ø§Ù„Ù…ÙØ§ØªÙŠØ­ Ø§Ù„Ù…ÙØ´ÙØ±Ø©"""
        
        data = json.dumps(self.keys).encode()
        encrypted_data = self.cipher.encrypt(data)
        
        self.keys_file.write_bytes(encrypted_data)
        
        # ØµÙ„Ø§Ø­ÙŠØ§Øª Ø§Ù„Ù‚Ø±Ø§Ø¡Ø© ÙÙ‚Ø· Ù„Ù„Ù…Ø§Ù„Ùƒ
        os.chmod(self.keys_file, 0o600)
    
    def store_key(self, provider: str, api_key: str, metadata: dict = None):
        """ØªØ®Ø²ÙŠÙ† Ù…ÙØªØ§Ø­ API"""
        
        self.keys[provider] = {
            "key": api_key,
            "metadata": metadata or {},
            "created_at": datetime.now().isoformat()
        }
        
        self._save_keys()
    
    def get_key(self, provider: str) -> str:
        """Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ù…ÙØªØ§Ø­ API"""
        
        key_data = self.keys.get(provider)
        
        if not key_data:
            raise KeyError(f"No API key for provider: {provider}")
        
        return key_data["key"]
    
    def delete_key(self, provider: str):
        """Ø­Ø°Ù Ù…ÙØªØ§Ø­"""
        
        if provider in self.keys:
            del self.keys[provider]
            self._save_keys()
```

---

## ğŸ“Š Usage Tracker (usage_tracker.py)

```python
import asyncpg
from datetime import datetime, date
from typing import Dict

class UsageTracker:
    """
    ØªØªØ¨Ø¹ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
    """
    
    def __init__(self, db_url: str = None):
        self.db_url = db_url or os.getenv("DATABASE_URL")
        self.pool = None
    
    async def initialize(self):
        """ØªÙ‡ÙŠØ¦Ø© Ø§ØªØµØ§Ù„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        
        self.pool = await asyncpg.create_pool(self.db_url)
    
    async def track_request(
        self,
        model_id: str,
        tokens: int,
        cost: float,
        success: bool,
        task_type: str = None,
        response_time_ms: int = 0,
        error_message: str = None
    ):
        """ØªØ³Ø¬ÙŠÙ„ Ø·Ù„Ø¨"""
        
        async with self.pool.acquire() as conn:
            await conn.execute("""
                INSERT INTO usage_logs
                (model_id, task_type, tokens_used, cost, response_time_ms, success, error_message)
                VALUES ($1, $2, $3, $4, $5, $6, $7)
            """, model_id, task_type, tokens, cost, response_time_ms, success, error_message)
            
            # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù…Ù„Ø®Øµ Ø§Ù„ÙŠÙˆÙ…ÙŠ
            await self._update_daily_summary(conn, model_id, tokens, cost, success)
    
    async def _update_daily_summary(
        self,
        conn,
        model_id: str,
        tokens: int,
        cost: float,
        success: bool
    ):
        """ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù…Ù„Ø®Øµ Ø§Ù„ÙŠÙˆÙ…ÙŠ"""
        
        today = date.today()
        
        await conn.execute("""
            INSERT INTO daily_usage_summary
            (date, model_id, total_requests, total_tokens, total_cost)
            VALUES ($1, $2, 1, $3, $4)
            ON CONFLICT (date, model_id)
            DO UPDATE SET
                total_requests = daily_usage_summary.total_requests + 1,
                total_tokens = daily_usage_summary.total_tokens + $3,
                total_cost = daily_usage_summary.total_cost + $4
        """, today, model_id, tokens, cost)
    
    async def get_model_usage(self, model_id: str) -> Dict:
        """Ø§Ø­ØµØ§Ø¦ÙŠØ§Øª Ù†Ù…ÙˆØ°Ø¬ Ù…Ø¹ÙŠÙ†"""
        
        async with self.pool.acquire() as conn:
            row = await conn.fetchrow("""
                SELECT
                    total_requests,
                    total_tokens,
                    total_cost,
                    success_rate
                FROM daily_usage_summary
                WHERE date = CURRENT_DATE AND model_id = $1
            """, model_id)
            
            if not row:
                return {
                    "requests_today": 0,
                    "tokens_today": 0,
                    "cost_today": 0.0,
                    "success_rate": 100.0
                }
            
            return {
                "requests_today": row['total_requests'],
                "tokens_today": row['total_tokens'],
                "cost_today": float(row['total_cost']),
                "success_rate": float(row['success_rate']) if row['success_rate'] else 100.0
            }
    
    async def get_daily_usage(self) -> Dict:
        """Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ÙŠÙˆÙ…"""
        
        async with self.pool.acquire() as conn:
            row = await conn.fetchrow("""
                SELECT
                    SUM(total_requests) as total_requests,
                    SUM(total_tokens) as total_tokens,
                    SUM(total_cost) as total_cost
                FROM daily_usage_summary
                WHERE date = CURRENT_DATE
            """)
            
            return {
                "total_requests": row['total_requests'] or 0,
                "total_tokens": row['total_tokens'] or 0,
                "total_cost": float(row['total_cost']) if row['total_cost'] else 0.0
            }
```

---

## ğŸ’° Cost Manager (cost_manager.py)

```python
class CostManager:
    """
    Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„ØªÙƒØ§Ù„ÙŠÙ
    """
    
    def __init__(self, pool_manager, daily_budget: float = 10.0):
        self.pool = pool_manager
        self.daily_budget = daily_budget
        self.alert_threshold = 0.8
    
    async def get_daily_cost(self) -> float:
        """Ø§Ù„ØªÙƒÙ„ÙØ© Ø§Ù„ÙŠÙˆÙ…ÙŠØ©"""
        
        usage = await self.pool.usage_tracker.get_daily_usage()
        return usage.get('total_cost', 0.0)
    
    async def check_budget(self) -> Dict:
        """ÙØ­Øµ Ø§Ù„Ù…ÙŠØ²Ø§Ù†ÙŠØ©"""
        
        daily_cost = await self.get_daily_cost()
        
        remaining = self.daily_budget - daily_cost
        percentage_used = (daily_cost / self.daily_budget) * 100
        
        status = "ok"
        if percentage_used >= 100:
            status = "exceeded"
        elif percentage_used >= self.alert_threshold * 100:
            status = "warning"
        
        return {
            "daily_budget": self.daily_budget,
            "daily_cost": daily_cost,
            "remaining": remaining,
            "percentage_used": percentage_used,
            "status": status
        }
    
    async def get_cost_breakdown(self) -> List[Dict]:
        """ØªÙˆØ²ÙŠØ¹ Ø§Ù„ØªÙƒØ§Ù„ÙŠÙ Ø­Ø³Ø¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬"""
        
        async with self.pool.usage_tracker.pool.acquire() as conn:
            rows = await conn.fetch("""
                SELECT
                    model_id,
                    total_cost,
                    total_requests
                FROM daily_usage_summary
                WHERE date = CURRENT_DATE
                ORDER BY total_cost DESC
            """)
            
            return [
                {
                    "model_id": row['model_id'],
                    "cost": float(row['total_cost']),
                    "requests": row['total_requests']
                }
                for row in rows
            ]
```

---

## ğŸ§ª Ù…Ø«Ø§Ù„ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…

```python
# example_usage.py
import asyncio
from model_pool import ModelPoolManager

async def main():
    # 1. ØªÙ‡ÙŠØ¦Ø© Model Pool
    pool = ModelPoolManager()
    
    # 2. Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¨Ø³ÙŠØ·
    response = await pool.execute_task(
        prompt="Ø§ÙƒØªØ¨ Ø¯Ø§Ù„Ø© Python Ù„Ø­Ø³Ø§Ø¨ Fibonacci",
        task_type="coding",
        priority="normal"
    )
    
    print(f"Model: {response.model_id}")
    print(f"Cost: ${response.cost:.4f}")
    print(f"Response: {response.content}")
    
    # 3. Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù…
    status = await pool.get_system_status()
    print(f"Daily cost: ${status['daily_cost']:.2f}/{status['cost_budget']:.2f}")
    
    # 4. Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ Ù…Ø­Ø¯Ø¯
    response = await pool.execute_task(
        prompt="Ø´Ø±Ø­ Ù…ÙÙ‡ÙˆÙ… Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¹Ù…ÙŠÙ‚",
        preferred_tier=ModelTier.FREE  # Ù…Ø¬Ø§Ù†ÙŠ ÙÙ‚Ø·
    )

if __name__ == "__main__":
    asyncio.run(main())
```

---

**Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„ØªØ§Ù„ÙŠØ©:** ØªÙ†ÙÙŠØ° Dashboard (React + FastAPI)
