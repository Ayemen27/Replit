# Phase 2C: Web Dashboard MVP - Requirements & Plan

## Ù†Ø¸Ø±Ø© Ø¹Ø§Ù…Ø©

**Ø§Ù„Ù‡Ø¯Ù**: Ø¨Ù†Ø§Ø¡ Web Dashboard Ø®ÙÙŠÙ Ù„Ø¹Ø±Ø¶ metrics ÙˆØ­Ø§Ù„Ø© workflows ÙÙŠ Ø§Ù„ÙˆÙ‚Øª Ø´Ø¨Ù‡ Ø§Ù„ÙØ¹Ù„ÙŠ  
**Ø§Ù„ÙÙ„Ø³ÙØ©**: Ø®ÙÙŠÙ Ø¹Ù„Ù‰ Ø§Ù„Ù…ÙˆØ§Ø±Ø¯ØŒ Ø¨Ø³ÙŠØ·ØŒ ÙØ¹Ø§Ù„  
**Ø§Ù„Ù…Ø¯Ø© Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©**: 3-4 Ø£ÙŠØ§Ù…  
**Ø§Ù„Ù…ÙˆØ§Ø±Ø¯ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©**: ~200 MB RAM Ø¥Ø¶Ø§ÙÙŠØ©

## Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© (Ù…ÙƒØªÙ…Ù„Ø© âœ…)

- âœ… CLI/TUI Interface Ø¬Ø§Ù‡Ø² ÙˆØ¹Ø§Ù…Ù„
- âœ… Async Workflows ØªØ¹Ù…Ù„ Ø¨Ù†Ø¬Ø§Ø­ (4 executors)
- âœ… Persistent State ÙÙŠ SQLite (WorkflowStorage)
- âœ… OpsCoordinator Ø¬Ø§Ù‡Ø² Ù…Ø¹ progress streaming
- âœ… Ø¬Ù…ÙŠØ¹ unit tests ØªÙ†Ø¬Ø­ (167/167)

## Ø§Ù„Ù…Ø±Ø§Ø­Ù„

### Ø§Ù„Ù…Ø±Ø­Ù„Ø© 1: Telemetry Endpoints (ÙŠÙˆÙ… 1)

**Ø§Ù„Ù‡Ø¯Ù**: Ø¥Ø¶Ø§ÙØ© FastAPI endpoints Ù„Ø¹Ø±Ø¶ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª

#### 1.1 Ø¥Ù†Ø´Ø§Ø¡ FastAPI Application Ù…Ø¹ Dependency Injection

**Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø¬Ø¯ÙŠØ¯**: `dev_platform/web/api_server.py`

```python
from fastapi import FastAPI, Depends, HTTPException, Header
from fastapi.responses import HTMLResponse
from fastapi.middleware.gzip import GZipMiddleware
from typing import Optional
import uvicorn
import os

from dev_platform.agents import get_ops_coordinator_agent
from dev_platform.core.workflow_storage import WorkflowStorage

# Application factory pattern
def create_app():
    app = FastAPI(
        title="AI Multi-Agent Platform Dashboard",
        version="2.2.0"
    )
    
    # Add gzip compression
    app.add_middleware(GZipMiddleware, minimum_size=1000)
    
    return app

app = create_app()

# Dependency injection for shared instances
async def get_coordinator():
    """Dependency: Returns singleton OpsCoordinator"""
    return get_ops_coordinator_agent()

async def get_storage():
    """Dependency: Returns WorkflowStorage instance from coordinator"""
    coordinator = get_ops_coordinator_agent()
    return coordinator.storage

async def get_metrics():
    """Dependency: Returns singleton MetricsProvider"""
    from dev_platform.web.metrics_provider import get_metrics_provider
    return get_metrics_provider()

# Simple token-based auth (production should use OAuth2)
API_TOKEN = os.getenv("DASHBOARD_API_TOKEN", "dev-token-change-in-production")

async def verify_token(x_api_token: Optional[str] = Header(None)):
    """Verify API token for authentication"""
    if x_api_token != API_TOKEN:
        raise HTTPException(status_code=401, detail="Invalid or missing API token")
    return x_api_token

# Health check (public, no auth)
@app.get("/api/health")
async def health_check():
    return {"status": "healthy", "version": "2.2.0"}

# Metrics endpoint (requires auth)
@app.get("/api/metrics")
async def get_system_metrics(
    metrics_provider = Depends(get_metrics),
    token: str = Depends(verify_token)
):
    """Get current system metrics from dedicated provider"""
    return await metrics_provider.get_system_metrics()

# Workflows endpoint (requires auth)
@app.get("/api/workflows")
async def get_workflows(
    storage = Depends(get_storage),
    token: str = Depends(verify_token),
    status: Optional[str] = None,
    limit: int = 100
):
    """Get workflows from storage
    
    By default, returns active workflows + recent history (combined).
    Can filter by status using ?status=completed|running|failed
    """
    if status:
        # Filter by specific status
        return await storage.get_workflows_by_status(status)
    else:
        # Return both active + recent history (combined view)
        active = await storage.get_active_workflows()
        history = await storage.get_workflow_history(limit=limit)
        
        # Combine and sort by created_at (most recent first)
        all_workflows = active + history
        all_workflows.sort(
            key=lambda w: w.get('created_at', ''), 
            reverse=True
        )
        return all_workflows[:limit]

# Workflow detail (requires auth)
@app.get("/api/workflows/{workflow_id}")
async def get_workflow_detail(
    workflow_id: str,
    storage = Depends(get_storage),
    token: str = Depends(verify_token)
):
    """Get workflow detail by ID"""
    workflow = await storage.get_workflow(workflow_id)
    if not workflow:
        raise HTTPException(status_code=404, detail="Workflow not found")
    return workflow

# Agent status (requires auth)
@app.get("/api/agents/status")
async def get_agent_status(
    coordinator = Depends(get_coordinator),
    token: str = Depends(verify_token)
):
    """Get status of all development agents"""
    return coordinator.get_agent_registry()
```

**Dependencies**:
- `fastapi==0.109.0` - Web framework (Ø®ÙÙŠÙ Ø¬Ø¯Ø§Ù‹)
- `uvicorn[standard]==0.27.0` - ASGI server Ù…Ø¹ compression
- `pydantic` - Data validation (Ù…Ø¯Ù…Ø¬ Ù…Ø¹ FastAPI)
- `python-multipart==0.0.6` - Form data support
- `aiosqlite` - Already installed (WorkflowStorage dependency)

**Dependency Injection Wiring**:
1. `get_coordinator()` â†’ Singleton OpsCoordinator
2. `get_storage()` â†’ coordinator.storage (already async SQLite)
3. `get_metrics()` â†’ Singleton MetricsProvider (dedicated service)
4. All dependencies injectable in tests (override with test doubles)

**Security Notes**:
- âœ… Simple token-based auth (X-API-Token header)
- âœ… Health check public, all other endpoints protected
- âš ï¸ Production should use OAuth2/JWT
- âš ï¸ If exposed beyond localhost, add HTTPS + IP whitelist

#### 1.2 Ø¥Ù†Ø´Ø§Ø¡ Metrics Provider (Dedicated Service)

**Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø¬Ø¯ÙŠØ¯**: `dev_platform/web/metrics_provider.py`

```python
"""
Dedicated Metrics Provider - Decoupled from business logic
Provides system metrics without coupling to OpsCoordinator
"""
import psutil
import asyncio
from datetime import datetime
from typing import Dict, Any
from functools import lru_cache

class MetricsProvider:
    """Lightweight metrics provider for telemetry"""
    
    def __init__(self):
        self._cache_ttl = 5  # seconds
        self._last_metrics = None
        self._last_update = None
    
    async def get_system_metrics(self) -> Dict[str, Any]:
        """Get current system metrics with caching
        
        Runs psutil in executor to avoid blocking the event loop.
        Caches results for 5 seconds to reduce overhead.
        """
        now = datetime.now()
        
        # Return cached if within TTL
        if (self._last_metrics and self._last_update and 
            (now - self._last_update).total_seconds() < self._cache_ttl):
            return self._last_metrics
        
        # Run psutil in executor (blocking I/O)
        loop = asyncio.get_event_loop()
        cpu = await loop.run_in_executor(None, psutil.cpu_percent, 0.5)
        mem = await loop.run_in_executor(None, lambda: psutil.virtual_memory().percent)
        disk = await loop.run_in_executor(None, lambda: psutil.disk_usage('/').percent)
        
        metrics = {
            "cpu_percent": cpu,
            "memory_percent": mem,
            "disk_percent": disk,
            "timestamp": now.isoformat()
        }
        
        # Update cache
        self._last_metrics = metrics
        self._last_update = now
        
        return metrics

# Singleton instance
_metrics_provider = None

def get_metrics_provider() -> MetricsProvider:
    """Get singleton MetricsProvider instance"""
    global _metrics_provider
    if _metrics_provider is None:
        _metrics_provider = MetricsProvider()
    return _metrics_provider
```

#### 1.3 Ø¥Ø¶Ø§ÙØ© Agent Registry Methods Ù„Ù„Ù€ OpsCoordinator

**Ø§Ù„ØªØ¹Ø¯ÙŠÙ„Ø§Øª Ø¹Ù„Ù‰**: `dev_platform/agents/ops_coordinator_agent.py`

```python
class OpsCoordinatorAgent:
    
    def get_agent_registry(self) -> Dict[str, Dict[str, Any]]:
        """Get registry of all development agents
        
        Returns status from singleton instances via factory functions.
        This is a READ-ONLY operation - no state changes.
        """
        from dev_platform.agents import (
            get_planner_agent,
            get_code_executor_agent,
            get_qa_test_agent
        )
        
        agents = {
            "planner": get_planner_agent(),
            "code_executor": get_code_executor_agent(),
            "qa_test": get_qa_test_agent(),
            "ops_coordinator": self
        }
        
        registry = {}
        for name, agent in agents.items():
            registry[name] = {
                "agent_id": agent.agent_id,
                "name": agent.name,
                "status": "running",  # Future: add actual health checks
                "permission_level": agent.permission_level
            }
        
        return registry
```

**Data Sources**:
- **System Metrics**: MetricsProvider (dedicated service, cached, async-safe)
- **Workflow Data**: WorkflowStorage (**already fully async** with aiosqlite)
- **Agent Status**: OpsCoordinator.get_agent_registry() via singleton getters
- **Architecture**: Clear separation of concerns - no business logic in metrics

#### 1.3 Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª API

**Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø¬Ø¯ÙŠØ¯**: `tests/unit/test_api_server.py`

```python
import pytest
from fastapi.testclient import TestClient
from dev_platform.web.api_server import app

client = TestClient(app)

def test_health_check():
    response = client.get("/api/health")
    assert response.status_code == 200
    assert response.json()["status"] == "healthy"

def test_get_metrics():
    response = client.get("/api/metrics")
    assert response.status_code == 200
    assert "cpu_percent" in response.json()

# 10+ Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø£Ø®Ø±Ù‰
```

**Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª**:
- âœ… `/api/health` - Health check (public)
- âœ… `/api/metrics` - System metrics JSON (auth required)
- âœ… `/api/workflows` - Combined workflows list JSON (active + history, auth required)
- âœ… `/api/workflows?status=running` - Filter by status (auth required)
- âœ… `/api/workflows/{id}` - Workflow detail (auth required)
- âœ… `/api/agents/status` - Agent status (auth required)
- âœ… `/api/metrics/partial` - HTMX HTML fragment via Jinja2 (XSS-safe, auth required)
- âœ… `/api/workflows/partial` - HTMX HTML fragment via Jinja2 (XSS-safe, shows active+history, auth required)
- âœ… 20+ Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª API

**Security**:
- âœ… All HTML partials use Jinja2 templates (auto-escaping)
- âœ… No raw f-string HTML interpolation (XSS prevention)

---

### Ø§Ù„Ù…Ø±Ø­Ù„Ø© 2: Web Dashboard UI (ÙŠÙˆÙ… 2-3)

**Ø§Ù„Ù‡Ø¯Ù**: Ø¨Ù†Ø§Ø¡ ÙˆØ§Ø¬Ù‡Ø© Ø¨Ø³ÙŠØ·Ø© Ù…Ø¹ HTMX + Bootstrap

#### 2.1 Ø¥Ù†Ø´Ø§Ø¡ HTML Templates

**Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø¬Ø¯ÙŠØ¯**: `dev_platform/web/templates/index.html`

```html
<!DOCTYPE html>
<html lang="ar" dir="rtl">
<head>
    <title>AI Multi-Agent Platform</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
    <script src="https://unpkg.com/htmx.org@1.9.10"></script>
</head>
<body>
    <nav class="navbar navbar-dark bg-dark">
        <div class="container-fluid">
            <span class="navbar-brand">AI Multi-Agent Platform</span>
        </div>
    </nav>
    
    <div class="container mt-4">
        <!-- System Metrics Card -->
        <div class="row">
            <div class="col-md-4">
                <div class="card">
                    <div class="card-header">System Metrics</div>
                    <div class="card-body" 
                         id="metrics"
                         hx-get="/api/metrics/partial" 
                         hx-trigger="load, every 10s" 
                         hx-headers='{"X-API-Token": "dev-token-change-in-production"}'>
                        Loading...
                    </div>
                </div>
            </div>
            
            <!-- Workflows Card -->
            <div class="col-md-8">
                <div class="card">
                    <div class="card-header">Recent Workflows</div>
                    <div class="card-body" 
                         id="workflows"
                         hx-get="/api/workflows/partial" 
                         hx-trigger="load, every 10s" 
                         hx-headers='{"X-API-Token": "dev-token-change-in-production"}'>
                        Loading...
                    </div>
                </div>
            </div>
        </div>
    </div>
    
    <!-- Note: Polling every 10s instead of 5s to reduce CPU usage -->
</body>
</html>
```

**Ù…Ø²Ø§ÙŠØ§ HTMX**:
- âœ… Ù„Ø§ JavaScript Ù…Ø¹Ù‚Ø¯
- âœ… **Polling ÙƒÙ„ 10 Ø«ÙˆØ§Ù†ÙŠ** ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ (optimized for CPU)
- âœ… Ø®ÙÙŠÙ Ø¬Ø¯Ø§Ù‹ (~10 KB)
- âœ… Ø³Ù‡Ù„ Ø§Ù„ØµÙŠØ§Ù†Ø©
- âœ… Built-in auth header support
- âœ… Uses FastAPI dependency injection (not globals)

#### 2.2 Ø¥Ø¶Ø§ÙØ© Template Rendering

**Ø§Ù„ØªØ¹Ø¯ÙŠÙ„Ø§Øª Ø¹Ù„Ù‰**: `dev_platform/web/api_server.py`

```python
from fastapi.templating import Jinja2Templates
from fastapi import Request

templates = Jinja2Templates(directory="dev_platform/web/templates")

@app.get("/", response_class=HTMLResponse)
async def dashboard(request: Request):
    """Main dashboard page"""
    return templates.TemplateResponse("index.html", {"request": request})

# HTMX partial responses (HTML fragments)
@app.get("/api/metrics/partial")
async def metrics_partial(
    metrics_provider = Depends(get_metrics),
    token: str = Depends(verify_token)
):
    """Metrics HTML fragment for HTMX polling
    
    Uses Jinja2 template for XSS safety.
    """
    metrics = await metrics_provider.get_system_metrics()
    
    # Render via Jinja2 template (XSS-safe)
    return templates.TemplateResponse(
        "partials/metrics.html",
        {"request": {}, "metrics": metrics}
    )
```

**New File**: `dev_platform/web/templates/partials/metrics.html`
```html
<div class="metrics-grid">
  <div class="metric">
    <strong>CPU:</strong> {{ "%.1f"|format(metrics.cpu_percent) }}%
  </div>
  <div class="metric">
    <strong>Memory:</strong> {{ "%.1f"|format(metrics.memory_percent) }}%
  </div>
  <div class="metric">
    <strong>Disk:</strong> {{ "%.1f"|format(metrics.disk_percent) }}%
  </div>
  <small class="text-muted">Last updated: {{ metrics.timestamp }}</small>
</div>
```

@app.get("/api/workflows/partial")
async def workflows_partial(
    storage = Depends(get_storage),
    token: str = Depends(verify_token),
    limit: int = 10
):
    """Workflows HTML fragment for HTMX polling
    
    Returns combined active + history (same as /api/workflows).
    Uses Jinja2 template to prevent XSS.
    """
    # Reuse same data logic as /api/workflows
    active = await storage.get_active_workflows()
    history = await storage.get_workflow_history(limit=limit)
    
    all_workflows = active + history
    all_workflows.sort(
        key=lambda w: w.get('created_at', ''), 
        reverse=True
    )
    workflows = all_workflows[:limit]
    
    # Render via Jinja2 template (XSS-safe)
    return templates.TemplateResponse(
        "partials/workflows.html",
        {"request": {}, "workflows": workflows}
    )
```

**Security Note**: Uses Jinja2 templates (auto-escaping) to prevent XSS from workflow names/descriptions

**New File**: `dev_platform/web/templates/partials/workflows.html`
```html
<div class="workflows-list">
  {% for wf in workflows %}
  <div class="workflow-item">
    <span class="badge bg-{{ 'success' if wf.status == 'completed' else 'primary' }}">
      {{ wf.status }}
    </span>
    <strong>{{ wf.workflow_type }}</strong>
    <small>{{ wf.get('project_name', 'N/A') }}</small>
    <small class="text-muted">{{ wf.get('created_at', '')[:10] }}</small>
  </div>
  {% endfor %}
  {% if workflows|length == 0 %}
  <p class="text-muted">No workflows yet</p>
  {% endif %}
</div>
```

**Note**: Renders all workflows passed (up to limit=10 from endpoint)

#### 2.3 Ø§Ù„ØµÙØ­Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©

1. **Dashboard** (`/`)
   - System metrics overview
   - Recent workflows (Ø¢Ø®Ø± 10)
   - Agent status summary

2. **Workflows** (`/workflows`)
   - Workflow history table
   - Filter by status
   - Search by ID

3. **Workflow Detail** (`/workflows/{id}`)
   - Full workflow details
   - Execution logs
   - Progress timeline

4. **Agent Status** (`/agents`)
   - Ø¬Ù…ÙŠØ¹ Ø§Ù„ÙˆÙƒÙ„Ø§Ø¡ Ø§Ù„Ù…Ø³Ø¬Ù„Ø©
   - Ø­Ø§Ù„Ø© ÙƒÙ„ ÙˆÙƒÙŠÙ„ (running, stopped, error)
   - Uptime & stats

**Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª**:
- âœ… 4 ØµÙØ­Ø§Øª HTML (main + 2 partials)
- âœ… Bootstrap styling
- âœ… **HTMX polling (ÙƒÙ„ 10 Ø«ÙˆØ§Ù†ÙŠ)** - uses `/api/*/partial` endpoints
- âœ… Jinja2 templates (XSS-safe, auto-escaping)
- âœ… Responsive design

**Template Files**:
- `templates/index.html` - Main dashboard
- `templates/partials/metrics.html` - Metrics fragment (XSS-safe)
- `templates/partials/workflows.html` - Workflows fragment (XSS-safe, active+history)

---

### Ø§Ù„Ù…Ø±Ø­Ù„Ø© 3: Integration & Testing (ÙŠÙˆÙ… 4)

#### 3.1 Ø¯Ù…Ø¬ Ù…Ø¹ main.py

**Ø§Ù„ØªØ¹Ø¯ÙŠÙ„Ø§Øª Ø¹Ù„Ù‰**: `main.py`

```python
def start_web_dashboard():
    """Start web dashboard server"""
    from dev_platform.web.api_server import app
    import uvicorn
    
    print("ğŸŒ Starting Web Dashboard on http://0.0.0.0:5000")
    uvicorn.run(app, host="0.0.0.0", port=5000)

# ÙÙŠ main()
if args.mode == 'web':
    start_web_dashboard()
```

**Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…**:
```bash
python main.py web
```

#### 3.2 Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Integration

**Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø¬Ø¯ÙŠØ¯**: `tests/integration/test_web_dashboard.py`

```python
import pytest
from fastapi.testclient import TestClient
from dev_platform.web.api_server import app

class TestWebDashboard:
    def test_dashboard_loads(self):
        client = TestClient(app)
        response = client.get("/")
        assert response.status_code == 200
        assert "AI Multi-Agent Platform" in response.text
    
    def test_metrics_updates(self):
        # Test polling endpoint
        pass
    
    def test_workflow_display(self):
        # Test workflow list
        pass
```

#### 3.3 ØªØ­Ø³ÙŠÙ†Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡

1. **Caching**:
   - Cache metrics Ù„Ù…Ø¯Ø© 5 Ø«ÙˆØ§Ù†ÙŠ
   - Cache workflow list Ù„Ù…Ø¯Ø© 2 Ø«Ø§Ù†ÙŠØ©

2. **Compression**:
   - gzip Ù„Ù„Ù€ responses (FastAPI middleware)

3. **Resource Limits**:
   - Max 100 workflows ÙÙŠ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©
   - Pagination Ù„Ù„Ù€ history

**Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª**:
- âœ… Integration tests (10+)
- âœ… Performance optimizations
- âœ… Documentation

---

## Ø§Ù„Ù…ÙˆØ§Ø±Ø¯ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©

### RAM Usage
- FastAPI + Uvicorn: ~80 MB
- HTMX/Bootstrap (client-side): 0 MB (ÙÙŠ Ø§Ù„Ù…ØªØµÙØ­)
- Templates rendering: ~20 MB
- Cache: ~50 MB
- **Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹**: ~150-200 MB

### Disk Usage
- Dependencies: ~30 MB (fastapi, uvicorn)
- Templates: ~100 KB
- Static files: ~50 KB (Ø¥Ø°Ø§ ÙˆØ¬Ø¯Øª)

### CPU Usage
- Idle: ~2%
- Peak: ~15% (Ø¹Ù†Ø¯ polling)

---

## Ø§Ù„ØªØ¨Ø¹ÙŠØ§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©

```txt
# Web Dashboard Dependencies
fastapi==0.109.0
uvicorn[standard]==0.27.0
jinja2==3.1.3
python-multipart==0.0.6
```

---

## Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©

### Unit Tests
- `test_api_server.py`: 15+ Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª API
- Coverage Ù‡Ø¯Ù: 80%+

### Integration Tests
- `test_web_dashboard.py`: 10+ Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª UI
- End-to-end workflow visualization

### Manual Testing Checklist
- [ ] Dashboard ÙŠØ¹Ø±Ø¶ metrics Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­
- [ ] **Polling ÙŠØ¹Ù…Ù„ ÙƒÙ„ 10 Ø«ÙˆØ§Ù†ÙŠ** (not 5s)
- [ ] HTMX calls `/api/metrics/partial` and `/api/workflows/partial` (HTML fragments)
- [ ] Workflow history ÙŠØ¸Ù‡Ø± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØµØ­ÙŠØ­Ø©
- [ ] Agent status ÙŠØ¹ÙƒØ³ Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„ÙØ¹Ù„ÙŠØ©
- [ ] Responsive Ø¹Ù„Ù‰ mobile/tablet
- [ ] Ù„Ø§ memory leaks Ø¨Ø¹Ø¯ Ø³Ø§Ø¹Ø© Ù…Ù† polling

---

## Ø§Ù„Ø¨Ø¯Ø§Ø¦Ù„ Ø§Ù„Ù…Ø¯Ø±ÙˆØ³Ø© ÙˆØ§Ù„Ù…Ø±ÙÙˆØ¶Ø©

### âŒ React Dashboard
- **Ø³Ø¨Ø¨ Ø§Ù„Ø±ÙØ¶**: ÙŠØ­ØªØ§Ø¬ 300+ MB RAM + build process Ù…Ø¹Ù‚Ø¯
- **Ø§Ù„Ø¨Ø¯ÙŠÙ„**: HTMX + Bootstrap (Ø®ÙÙŠÙ Ø¬Ø¯Ø§Ù‹)

### âŒ WebSocket Real-time
- **Ø³Ø¨Ø¨ Ø§Ù„Ø±ÙØ¶**: ØªØ¹Ù‚ÙŠØ¯ Ø¥Ø¶Ø§ÙÙŠ + Ù…ÙˆØ§Ø±Ø¯ server
- **Ø§Ù„Ø¨Ø¯ÙŠÙ„**: **Polling ÙƒÙ„ 10 Ø«ÙˆØ§Ù†ÙŠ** (ÙƒØ§ÙÙŠ Ù„Ù…Ø¹Ø¸Ù… Ø§Ù„Ø­Ø§Ù„Ø§Øª + CPU-friendly)

### âŒ Grafana/Kibana
- **Ø³Ø¨Ø¨ Ø§Ù„Ø±ÙØ¶**: heavy dependencies (500+ MB RAM)
- **Ø§Ù„Ø¨Ø¯ÙŠÙ„**: Custom lightweight dashboard

---

## Ø®Ø·Ø© Ø§Ù„ØªÙ†ÙÙŠØ°

### Day 1: Telemetry Endpoints
- ØµØ¨Ø§Ø­Ø§Ù‹: Ø¥Ù†Ø´Ø§Ø¡ `api_server.py` + basic endpoints
- Ø¨Ø¹Ø¯ Ø§Ù„Ø¸Ù‡Ø±: Ø¯Ù…Ø¬ OpsCoordinator + WorkflowStorage
- Ù…Ø³Ø§Ø¡Ù‹: Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª API

### Day 2: UI Development
- ØµØ¨Ø§Ø­Ø§Ù‹: HTML templates + Bootstrap setup
- Ø¨Ø¹Ø¯ Ø§Ù„Ø¸Ù‡Ø±: HTMX integration + polling
- Ù…Ø³Ø§Ø¡Ù‹: Dashboard ØµÙØ­Ø© + Workflows ØµÙØ­Ø©

### Day 3: More Pages & Polish
- ØµØ¨Ø§Ø­Ø§Ù‹: Workflow detail ØµÙØ­Ø© + Agent status ØµÙØ­Ø©
- Ø¨Ø¹Ø¯ Ø§Ù„Ø¸Ù‡Ø±: Styling & responsive design
- Ù…Ø³Ø§Ø¡Ù‹: UI testing

### Day 4: Integration & Testing
- ØµØ¨Ø§Ø­Ø§Ù‹: Ø¯Ù…Ø¬ Ù…Ø¹ main.py + CLI
- Ø¨Ø¹Ø¯ Ø§Ù„Ø¸Ù‡Ø±: Integration tests
- Ù…Ø³Ø§Ø¡Ù‹: Performance testing + documentation

---

## Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ù†Ø¬Ø§Ø­

- âœ… Dashboard ÙŠØ¹Ù…Ù„ Ø¹Ù„Ù‰ `http://localhost:5000`
- âœ… ÙŠØ¹Ø±Ø¶ system metrics ÙÙŠ Ø§Ù„ÙˆÙ‚Øª Ø´Ø¨Ù‡ Ø§Ù„ÙØ¹Ù„ÙŠ (**ÙƒÙ„ 10 Ø«ÙˆØ§Ù†ÙŠ**)
- âœ… HTMX polls `/api/metrics/partial` and `/api/workflows/partial` (HTML fragments, not JSON)
- âœ… ÙŠØ¹Ø±Ø¶ workflow history Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­ (active + history combined)
- âœ… ÙŠØ¹Ø±Ø¶ agent status
- âœ… Ø¬Ù…ÙŠØ¹ endpoints ØªØ³ØªØ®Ø¯Ù… FastAPI dependency injection (no globals)
- âœ… Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª ØªÙ†Ø¬Ø­ (20+ API + 10+ UI)
- âœ… Ø§Ø³ØªÙ‡Ù„Ø§Ùƒ Ø§Ù„Ù…ÙˆØ§Ø±Ø¯ Ø£Ù‚Ù„ Ù…Ù† 200 MB RAM
- âœ… Ù„Ø§ LSP errors
- âœ… Documentation ÙƒØ§Ù…Ù„Ø©

---

## Ø§Ù„Ø®Ø·ÙˆØ© Ø§Ù„ØªØ§Ù„ÙŠØ© Ø¨Ø¹Ø¯ Phase 2C

Ø¨Ø¹Ø¯ Ø¥ÙƒÙ…Ø§Ù„ Web Dashboard MVP:
1. **Ø¥Ø¹Ø§Ø¯Ø© ØªÙØ¹ÙŠÙ„ Integration Tests** - refactor ModelRouter API
2. **Phase 3**: Advanced Features (Ø§Ø®ØªÙŠØ§Ø±ÙŠØ©)
   - WebSocket Ù„Ù„Ù€ real-time updates
   - Advanced metrics & analytics
   - Multi-user support
3. **Production Deployment** - Deploy Ø¹Ù„Ù‰ Ø§Ù„Ø³ÙŠØ±ÙØ± Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ

---

## Architect Review Notes & Improvements

**ØªØ§Ø±ÙŠØ® Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹Ø©**: 2025-11-15 (2 iterations)

### First Iteration Issues:
1. âŒ Dependency injection only sketched via singleton getters
2. âŒ Telemetry sourcing tightly coupled to OpsCoordinator (psutil directly)
3. âš ï¸ Async access pattern unclear (WorkflowStorage already async but not documented)

### Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª Ø§Ù„Ù…Ø·Ø¨Ù‚Ø© (Iteration 2):

1. **Dependency Injection Pattern** âœ…
   - FastAPI dependencies Ø¨Ø´ÙƒÙ„ ÙˆØ§Ø¶Ø­:
     - `get_coordinator()` â†’ Singleton OpsCoordinator
     - `get_storage()` â†’ coordinator.storage (async SQLite)
     - `get_metrics()` â†’ Singleton MetricsProvider
   - Application factory pattern (`create_app()`)
   - All dependencies overridable in tests

2. **Telemetry Data Sources** âœ…âœ…
   - **MetricsProvider dedicated service** (NEW!)
     - Decoupled from OpsCoordinator business logic
     - Built-in caching (5s TTL)
     - Async-safe (psutil in executor)
   - Workflow data: WorkflowStorage (**confirmed fully async** with aiosqlite)
   - Agent status: OpsCoordinator.get_agent_registry() (read-only, singleton getters)

3. **Async Data Access Patterns** âœ…âœ…
   - All API handlers async/await
   - WorkflowStorage already fully async (aiosqlite) - **no refactoring needed**
   - MetricsProvider runs psutil in executor (non-blocking)
   - No connection pooling needed (aiosqlite handles it internally)

4. **Security & Authentication** âœ…
   - Token-based auth (X-API-Token header)
   - Health check public, all others protected
   - Production notes: OAuth2/JWT + HTTPS + IP whitelist

5. **Polling Optimization** âœ…
   - **10 seconds polling interval** (CPU-friendly)
   - MetricsProvider caching (5s TTL, refreshed on demand)
   - gzip compression middleware

6. **Resource Management** âœ…
   - aiosqlite connection management (built-in)
   - gzip compression
   - Max 100 workflows pagination

### Next Steps After Approval:
1. Implement dependency injection wiring
2. Add comprehensive async tests
3. Document authentication flow
4. Begin Day 1 implementation

---

**Ø¢Ø®Ø± ØªØ­Ø¯ÙŠØ«**: 2025-11-15 (post-architect-review)  
**Ø§Ù„Ø­Ø§Ù„Ø©**: Ù…Ø³ØªÙ†Ø¯ Ù…Ø­Ø³Ù‘Ù† ÙˆØ¬Ø§Ù‡Ø² Ù„Ù„ØªÙ†ÙÙŠØ°  
**Ø§Ù„Ù…ÙˆØ§ÙÙ‚Ø©**: ÙÙŠ Ø§Ù†ØªØ¸Ø§Ø± Ù…ÙˆØ§ÙÙ‚Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù„Ù„Ø¨Ø¯Ø¡
